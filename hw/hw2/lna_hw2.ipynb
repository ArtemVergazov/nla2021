{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9v1vX4-OGIT"
   },
   "source": [
    "# Problem set 2 (45 + 50 + 33 + 15 = 143 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOMNJ4TcOGIV"
   },
   "source": [
    "## Problem 1 (LU decomposition) 45 pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYHDl6ppOGIV"
   },
   "source": [
    "### 1. LU  for band matrices and Cholesky decomposition (13 pts)\n",
    "\n",
    "The complexity to find an LU decomposition of a dense $n\\times n$ matrix is $\\mathcal{O}(n^3)$.\n",
    "Significant reduction in complexity can be achieved if the matrix has a certain structure, e.g. it is sparse. \n",
    "In the following task we consider an important example of $LU$ for a special type of matrices –– band matrices with top left entry equal to 1 and the bandwidth $m$ equal to 3 or 5 which called tridiagonal and pentadiagonal respectively. The bands may be ```[1, 2, 1]``` and ```[1, 1, 2, 1, 1]``` respectively\n",
    "\n",
    "- (4 pts) Write a function ```band_lu(diag_broadcast, n)``` which computes LU decomposition for tridiagonal or pentadiagonal matrix with top left entry equal to 1 with given diagonal bands. \n",
    "For example, input parametres ```(diag_broadcast = [1,2,1], n = 4)``` mean that we need to find LU decomposition for the triangular matrix of the form:\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "1 & 1 & 0 & 0\\\\\n",
    "1 & 2 & 1 & 0 \\\\\n",
    "0 & 1 & 2 & 1 \\\\\n",
    "0 & 0 & 1 & 2 \\\\\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "Provide the extensive testing of the implemented function that will works correctly for large $n$,  e.g. $n=100$.\n",
    "As an output it is considered to make ```L``` and ```U``` - 2D arrays representing diagonals in factors $L$ (```L[0]``` keeps first lower diagonal, ```L[1]``` keeps second lower, ...), and $U$ (```U[:,0]``` keeps main diagonal, ```U[:,1]``` keeps first upper, ...).\n",
    "\n",
    "- (2 pts) Compare execution time of the band LU decomposition using standard function from ```scipy```, i.e. which takes the whole matrix and does not know about its special structure, and band decomposition of yours implementation. Comment on the results.\n",
    "\n",
    "- (7 pts) Write a function ```cholesky(n)``` for computing Cholesky decomposition. It should take the the single argument - the matrix that will be factorized and return the single output - lower-triangular factor $L$. Think about the efficiency of your implementation and if necessary update it to achieve the best performance (eliminate Python loops, where it is possible and so on). Explicitly describe the difference with LU decomposition that reduces the complexity from $2n^3/3$ for LU to $n^3/3$ for Cholesky. \n",
    "Test the implemented function on the Pascal matrix of given size $n$ for $n = 5, 10, 50$. \n",
    "Pascal matrix is square matrix of the following form (here for $n=4$)\n",
    "$$P = \\begin{pmatrix}\n",
    "1 & 1 & 1 & 1\\\\\n",
    "1 & 2 & 3 & 4 \\\\\n",
    "1 & 3 & 6 & 10 \\\\\n",
    "1 & 4 & 10 & 20 \\\\\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "    [Here](https://en.wikipedia.org/wiki/Pascal_matrix) you can find more details about such matrices and analytical form for factor $L$ from Cholesky decomposition. Compare the result of your implementation with analytical expression in terms of some matrix norm of difference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "BvY7icWBOGIW"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import diags # can be used with broadcasting of scalars if desired dimensions are large\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# INPUT : diag_broadcast - list of diagonals value to broadcast,length equal to 3 or 5; n - integer, band matrix shape.\n",
    "# OUTPUT : L - 2D np.ndarray, L.shape[0] depends on bandwidth, L.shape[1] = n-1, do not store main diagonal, where all ones;\n",
    "#          add zeros to the right side of rows to handle with changing length of diagonals.\n",
    "#          U - 2D np.ndarray, U.shape[0] = n, U.shape[1] depends on bandwidth;\n",
    "#          add zeros to the bottom of columns to handle with changing length of diagonals.\n",
    "def band_lu(d_b, n): #d_b is a diag_broadcast\n",
    "  m = len(d_b)\n",
    "  if(m==3):\n",
    "    L=np.zeros((1,n-1))\n",
    "    U=np.zeros((n,2))\n",
    "    U[0,0]=1\n",
    "    L[0,0]=d_b[0]\n",
    "    for i in range(1,n-1):\n",
    "      L[0,i]=d_b[0]/(d_b[1]-d_b[2]*L[0,i-1])\n",
    "      U[i,0]=d_b[1]-L[0,i-1]*d_b[2]\n",
    "      U[i-1,1]=d_b[2]\n",
    "    U[-1,0]=d_b[1]-L[0,-1]*d_b[2]\n",
    "    U[-2,1]=d_b[2]\n",
    "\n",
    "  elif(m==5):\n",
    "    L=np.zeros((2,n-1))\n",
    "    U=np.zeros((n,3))\n",
    "    U[0,0]=1\n",
    "    U[0,1]=d_b[3]\n",
    "    U[0,2]=d_b[4]\n",
    "    \n",
    "    L[0,0]=d_b[1]/U[0,0]\n",
    "    U[1,0]=d_b[2]-L[0,0]*U[0,1]\n",
    "    U[1,1]=d_b[3]-L[0,0]*U[0,2]\n",
    "    U[1,2]=d_b[4]\n",
    "\n",
    "    for i in range(0,n-2):\n",
    "      L[1,i]=d_b[0]/U[i,0]\n",
    "      L[0,i+1]=( d_b[1]-L[1,i]*U[i,1] )/U[i+1,0]\n",
    "      \n",
    "      U[i+2,0]=d_b[2]-L[1,i]*U[i,2]-L[0,i+1]*U[1+i,1]\n",
    "      U[i+2,1]=d_b[3]-L[0,i+1]*U[i+1,2]\n",
    "      U[i+2,2]=d_b[4]\n",
    "    U[-2,2]=0\n",
    "    U[-1,2]=0\n",
    "    U[-1,1]=0\n",
    "    L[1,-1]=0\n",
    "  return L,U\n",
    "    \n",
    "def cholesky(A):\n",
    "    n = len(A)\n",
    "\n",
    "    L = np.zeros((n,n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for k in range(i+1):\n",
    "            tmp_sum = sum(L[i,j] * L[k,j] for j in range(k))\n",
    "            \n",
    "            if (i == k): # Diagonal elements\n",
    "                if(A[i][i] - tmp_sum < 0):\n",
    "                  print(f\"We need to take a sqrt of the negative number of  A[i][i]-tmp_sum for A[i][i]= { A[i][i] } and tmp_sum = {tmp_sum}\\n\")\n",
    "                L[i,k] =sqrt(A[i][i] - tmp_sum)\n",
    "            else:\n",
    "                L[i,k] = (1.0 / L[k,k] * (A[i][k] - tmp_sum))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KD7yUvo5XwuB"
   },
   "source": [
    "1. band_lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HUQvSJHSnw8"
   },
   "outputs": [],
   "source": [
    "L,U=band_lu([4,2,7],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNP831vFSnlf",
    "outputId": "0d0b10ea-3929-4325-8ab7-db3c31233ac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.        , -0.15384615,  1.3       , -0.56338028]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOZ1ywQPTAP3",
    "outputId": "44c166c1-5a21-469c-dd95-aa68520a0a68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   7.        ],\n",
       "       [-26.        ,   7.        ],\n",
       "       [  3.07692308,   7.        ],\n",
       "       [ -7.1       ,   7.        ],\n",
       "       [  5.94366197,   0.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsKIbeT1Weg7"
   },
   "outputs": [],
   "source": [
    "L,U=band_lu([4,2,7,8,9],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJip7MJ7XogO",
    "outputId": "c8720189-a7b5-446c-d4d4-e659618cb803"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.        ,   3.33333333,  -0.56410256, -15.81818182],\n",
       "       [  4.        ,  -0.44444444,   0.92307692,   0.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhfDOaV2Xpo9",
    "outputId": "204f0b80-fc76-4a91-b281-6db8548fbc5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   8.        ,   9.        ],\n",
       "       [ -9.        , -10.        ,   9.        ],\n",
       "       [  4.33333333, -22.        ,   9.        ],\n",
       "       [ -1.41025641,  13.07692308,   0.        ],\n",
       "       [205.54545455,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvZiH34oYSgx"
   },
   "source": [
    "2. Time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shQvJK-DPvz4"
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import lu\n",
    "n=1000\n",
    "A=np.zeros((n,n))\n",
    "diag_broadcast = [4,2,7]\n",
    "A[0,0]=1\n",
    "A[0,1]=diag_broadcast[2]\n",
    "for i in range(n-2):\n",
    "  A[i+1,i:(i+3)]=diag_broadcast\n",
    "A[-1,-2:]=diag_broadcast[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYTjzA2ZPvwM",
    "outputId": "a0551e68-b79f-433d-bc2c-ddae43524f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 5: 42.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "p , l , u = lu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MZRnj-_YGpv",
    "outputId": "c246b1c6-616e-4548-bc7c-0beda82393e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 2.61 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "L,U=band_lu([4,2,7],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhXKwH4RYNUP",
    "outputId": "08e023b0-b32f-46f0-a3d1-98ed3313dc8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 5: 4.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "L,U=band_lu([4,2,7,8,9],1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaD6T0sFZcg9"
   },
   "source": [
    "3.Cholesky decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_eJZc_9NZe_F",
    "outputId": "e174aedd-cb5d-4e55-fd15-7bb312d2b51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 5\n",
      "\n",
      "A:\n",
      " [[ 1  1  1  1  1]\n",
      " [ 1  2  3  4  5]\n",
      " [ 1  3  6 10 15]\n",
      " [ 1  4 10 20 35]\n",
      " [ 1  5 15 35 70]]\n",
      "L:\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [1. 2. 1. 0. 0.]\n",
      " [1. 3. 3. 1. 0.]\n",
      " [1. 4. 6. 4. 1.]]\n",
      "n = 10\n",
      "\n",
      "A:\n",
      " [[    1     1     1     1     1     1     1     1     1     1]\n",
      " [    1     2     3     4     5     6     7     8     9    10]\n",
      " [    1     3     6    10    15    21    28    36    45    55]\n",
      " [    1     4    10    20    35    56    84   120   165   220]\n",
      " [    1     5    15    35    70   126   210   330   495   715]\n",
      " [    1     6    21    56   126   252   462   792  1287  2002]\n",
      " [    1     7    28    84   210   462   924  1716  3003  5005]\n",
      " [    1     8    36   120   330   792  1716  3432  6435 11440]\n",
      " [    1     9    45   165   495  1287  3003  6435 12870 24310]\n",
      " [    1    10    55   220   715  2002  5005 11440 24310 48620]]\n",
      "L:\n",
      " [[  1.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.   1.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.   2.   1.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.   3.   3.   1.   0.   0.   0.   0.   0.   0.]\n",
      " [  1.   4.   6.   4.   1.   0.   0.   0.   0.   0.]\n",
      " [  1.   5.  10.  10.   5.   1.   0.   0.   0.   0.]\n",
      " [  1.   6.  15.  20.  15.   6.   1.   0.   0.   0.]\n",
      " [  1.   7.  21.  35.  35.  21.   7.   1.   0.   0.]\n",
      " [  1.   8.  28.  56.  70.  56.  28.   8.   1.   0.]\n",
      " [  1.   9.  36.  84. 126. 126.  84.  36.   9.   1.]]\n",
      "We need to take a sqrt of the negative number of  A[i][i]-tmp_sum for A[i][i]= 30067266499541040 and tmp_sum = 3.0067266499541216e+16\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-7fec9ac2f5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpascal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"n = {i}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-b657c79057f6>\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtmp_sum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"We need to take a sqrt of the negative number of  A[i][i]-tmp_sum for A[i][i]= { A[i][i] } and tmp_sum = {tmp_sum}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtmp_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtmp_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import pascal\n",
    "for i in [5,10,50]:\n",
    "  A = pascal(i)\n",
    "  L = cholesky(A)\n",
    "  print(f\"n = {i}\\n\")\n",
    "  print(\"A:\\n\",np.array(A))\n",
    "  print(\"L:\\n\",L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iM6NwHQOGId"
   },
   "source": [
    "### 2. Stability of LU (8 pts)\n",
    "\n",
    "* (4 pts) Show, that for these  matrices $A$ and $B$ LU decomposition fails. Why does it happen?\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "2 & 3\n",
    "\\end{pmatrix}.$ \n",
    "\n",
    "$B = \\begin{pmatrix}\n",
    "1 & 1 & 0\\\\\n",
    "1 & 1 & 2 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{pmatrix}.$ \n",
    "\n",
    "* (4 pts) In the LU decomposition, a pivot position is a position of the element that identifies the row and column that will be eliminated in the current step. For example, first pivot in LU is usually the left top element. What value of $c$ leads to zero in the second pivot position? What $c$ produces zero in the third pivot position? What modification of LU should we use in order to address the possible zeros in pivot position?\n",
    "\n",
    "$A = \\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "2 & 4 & 1 \\\\\n",
    "3 & 5 & 1\n",
    "\\end{pmatrix}.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0S3-YK0lV6g"
   },
   "source": [
    "##### * (4 pts) Show, that for these  matrices $A$ and $B$ LU decomposition fails. Why does it happen?\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "A = \\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "2 & 3\n",
    "\\end{pmatrix}.$ \n",
    "\n",
    "$B = \\begin{pmatrix}\n",
    "1 & 1 & 0\\\\\n",
    "1 & 1 & 2 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{pmatrix}.$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8Mu3wIzljkT"
   },
   "source": [
    "$\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "2 & 3\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "l & 1\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} \\\\\n",
    "0 & u_{21}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} \\\\\n",
    "l·u_{11} & l·u_{12}+u_{21}\n",
    "\\end{pmatrix}\n",
    "=|u_{11}=0,u_{12}=1|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "l·0 & l·1+u_{21}\n",
    "\\end{pmatrix}\n",
    "$ \n",
    "$l=2/0 \\Rightarrow $decomposition fails\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KajjrwTjo67g"
   },
   "source": [
    "$B =\n",
    "\\begin{pmatrix}\n",
    "1 & 1 & 0\\\\\n",
    "1 & 1 & 2 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "l_1 & 1 & 0 \\\\\n",
    "l_3 & l_2 & 1\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} & u_{13}\\\\\n",
    "0 & u_{21} & u_{22} \\\\\n",
    "0 & 0 & u_{31}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} & u_{13}\\\\\n",
    "l_1 \\cdot u_{11} & l_1 \\cdot u_{12}+u_{21} & l_1 \\cdot u_{13}+u_{22} \\\\\n",
    "l_3 \\cdot u_{11} & l_3 \\cdot u_{12}+l_2 \\cdot u_{21} & l_3 \\cdot u_{13}+l_2 \\cdot u_{22} + u_{31}\n",
    "\\end{pmatrix}\n",
    "=|u_{11}=1,u_{12}=1,u_{13}=0|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & 1 & 0\\\\\n",
    "l_1 \\cdot 1 & l_1 \\cdot 1+u_{21} & l_1 \\cdot 0+u_{22} \\\\\n",
    "l_3 \\cdot 1 & l_3 \\cdot 1+l_2 \\cdot u_{21} & l_3 \\cdot 0+l_2 \\cdot u_{22} + u_{31}\n",
    "\\end{pmatrix}\n",
    "$\n",
    "Then\n",
    "$l_1 = 1, u_{21}=0, u_{22}=2, l_3=1,l_2=(2-1)/0 \\Rightarrow$ decomposition fails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDz4tWkFo6yd"
   },
   "source": [
    "decomposition fails because during decomposition we need to divide by zero: these matrixes are not strictly regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkC0cWbGsdqw"
   },
   "source": [
    "##### (4 pts) In the LU decomposition, a pivot position is a position of the element that identifies the row and column that will be eliminated in the current step. For example, first pivot in LU is usually the left top element. What value of $c$ leads to zero in the second pivot position? What $c$ produces zero in the third pivot position? What modification of LU should we use in order to address the possible zeros in pivot position?\n",
    "\n",
    "$A = \\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "2 & 4 & 1 \\\\\n",
    "3 & 5 & 1\n",
    "\\end{pmatrix}.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX9SWtbusgiq"
   },
   "source": [
    "if $4-\\dfrac{2}{1}\\cdot c = 0$, then $c=2$ leads to zero in second pivot position\\\n",
    "$A = \n",
    "\\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "2 & 4 & 1 \\\\\n",
    "3 & 5 & 1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "l_1 & 1 & 0 \\\\\n",
    "l_3 & l_2 & 1\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} & u_{13}\\\\\n",
    "0 & u_{21} & u_{22} \\\\\n",
    "0 & 0 & u_{31}\n",
    "\\end{pmatrix}\n",
    "=|\\text{zero in the third pivot position} \\Rightarrow u_{31}=0|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "u_{11} & u_{12} & u_{13}\\\\\n",
    "l_1 \\cdot u_{11} & l_1 \\cdot u_{12}+u_{21} & l_1 \\cdot u_{13}+u_{22} \\\\\n",
    "l_3 \\cdot u_{11} & l_3 \\cdot u_{12}+l_2 \\cdot u_{21} & l_3 \\cdot u_{13}+l_2 \\cdot u_{22}\n",
    "\\end{pmatrix}\n",
    "=|u_{11}=1,u_{12}=c,u_{13}=0|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "l_1 \\cdot 1 & l_1 \\cdot c+u_{21} & l_1 \\cdot 0+u_{22} \\\\\n",
    "l_3 \\cdot 1 & l_3 \\cdot c+l_2 \\cdot u_{21} & l_3 \\cdot 0+l_2 \\cdot u_{22}\n",
    "\\end{pmatrix}\n",
    "=|l_1=2,l_3=3|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "2 & 2\\cdot c+u_{21} & u_{22} \\\\\n",
    "3 & 3\\cdot c+l_2 \\cdot u_{21} & l_2 \\cdot u_{22}\n",
    "\\end{pmatrix}\n",
    "=|u_{22}=1|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "2 & 2\\cdot c+u_{21} & 1 \\\\\n",
    "3 & 3\\cdot c+l_2 \\cdot u_{21} & l_2\n",
    "\\end{pmatrix}\n",
    "=|l_2=1|\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & c & 0\\\\\n",
    "2 & 2\\cdot c+u_{21} & 1 \\\\\n",
    "3 & 3\\cdot c+u_{21} & 1\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\left\\{\\begin{matrix}\n",
    "2\\cdot c + u_{21} &= 4  \\\\\n",
    "3\\cdot c + u_{21} &= 5  \\\\\n",
    "\\end{matrix}\\right.\\Rightarrow c=1 \\text{ leads to zero in third pivot position }\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-kb8s9czV0O"
   },
   "source": [
    "We need to use PLU decomposition in order to address the possible zeros in pivot position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc3BR_TOGIj"
   },
   "source": [
    "### 3. Implementation of PLU decomposition (14 pts)\n",
    "\n",
    "As you have noticed before, LU decomposition may fail. In order to make it stable, we can use LU decomposition with pivoting  (PLU).\n",
    "\n",
    "We want to find such permutation matrix $P$ that LU decomposition of $PA$ exists\n",
    "\n",
    "$$ PA = LU $$\n",
    "\n",
    "- (7 pts) Implement efficiently PLU decomposition (without loops and with appropriate level of BLAS operations).  Also, pay attention to the way of permutation matrix storage.\n",
    "\n",
    "- (4 pts ) Compare your function for computing PLU with built-in function on matrices of such type ```(mirror_diag = [1,2,1], n = 4)```. (Bandwidth and matrix size may vary). So, you can pass them as dense 2D NumPy array and do not tune your implementation to this special structure. Compare them in terms of running time (use ```%timeit``` magic) for range of dimensions to recover the asymptotic rate of time increasing and in terms of acuracy. We expect you plot the running time vs matrix dimension for built-in function and your implementation. So you should get the plot with two lines.\n",
    "Consider additionally one of the pathological examples from above, where LU fails, but PLU has to work.\n",
    "\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "0 & 0 & 1 & 1 \\\\\n",
    " 0 &1 & 2 & 1  \\\\\n",
    " 1 & 2 & 1  & 0\\\\\n",
    "1 & 2  & 0 & 0  \\\\\n",
    "\\end{pmatrix}.$$\n",
    "\n",
    "\n",
    "- (3 pts) Discuss the obtained results and explain how is it possible to accelerate computing the PLU factorization. \n",
    "\n",
    "NumPy or JAX are both ok in this problem, but please use the single library for all implementations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjBFtzD-1oow"
   },
   "source": [
    "##### - (7 pts) Implement efficiently PLU decomposition (without loops and with appropriate level of BLAS operations).  Also, pay attention to the way of permutation matrix storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DZSMhSv1pOe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pivot_matrix(M):\n",
    "    \"\"\"Returns the pivoting matrix for M, used in Doolittle's method.\"\"\"\n",
    "    m = len(M)\n",
    "\n",
    "    id_mat = np.identity(m, dtype='float')\n",
    "\n",
    "    # Rearrange the identity matrix such that the largest element of                                                                                                                                                                                   \n",
    "    # each column of M is placed on the diagonal of of M                                                                                                                                                                                               \n",
    "    for j in range(m):\n",
    "        row = max(range(j, m), key=lambda i: abs(M[i][j]))\n",
    "        if j != row:\n",
    "            # Swap the rows                                                                                                                                                                                                                            \n",
    "            id_mat[j], id_mat[row] = id_mat[row], id_mat[j]\n",
    "\n",
    "    return id_mat\n",
    "\n",
    "def lu_decomposition(A):\n",
    "    \"\"\"Performs an LU Decomposition of A (which must be square)                                                                                                                                                                                        \n",
    "    into PA = LU. The function returns P, L and U.\"\"\"\n",
    "    A=np.array(A)\n",
    "    n = len(A)\n",
    "\n",
    "    # Create zero matrices for L and U                                                                                                                                                                                                                 \n",
    "    L = np.zeros((n,n))\n",
    "    U = np.zeros((n,n))\n",
    "\n",
    "    # Create the pivot matrix P and the multipled matrix PA                                                                                                                                                                                            \n",
    "    P = pivot_matrix(A)\n",
    "    PA = np.matmul(P, A)\n",
    "\n",
    "    # Perform the LU Decomposition                                                                                                                                                                                                                     \n",
    "    for j in range(n):\n",
    "        # All diagonal entries of L are set to unity                                                                                                                                                                                                   \n",
    "        L[j,j] = 1.0\n",
    "\n",
    "        # LaTeX: u_{ij} = a_{ij} - \\sum_{k=1}^{i-1} u_{kj} l_{ik}                                                                                                                                                                                      \n",
    "        for i in range(j+1):\n",
    "            s1 = sum(U[k,j] * L[i,k] for k in range(i))\n",
    "            U[i,j] = PA[i,j] - s1\n",
    "\n",
    "        # LaTeX: l_{ij} = \\frac{1}{u_{jj}} (a_{ij} - \\sum_{k=1}^{j-1} u_{kj} l_{ik} )                                                                                                                                                                  \n",
    "        for i in range(j, n):\n",
    "            s2 = sum(U[k,j] * L[i,k] for k in range(j))\n",
    "            L[i,j] = (PA[i,j] - s2) / U[j,j]\n",
    "\n",
    "    return (P, L, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73gXFO9x5QvQ",
    "outputId": "dc3c497f-6d14-477b-e995-bed8520e7898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[7, 3, -1, 2], [3, 8, 1, -4], [-1, 1, 4, -1], [2, -4, -1, 6]]\n",
      "P:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "PA:\n",
      " [[ 7.  3. -1.  2.]\n",
      " [ 3.  8.  1. -4.]\n",
      " [-1.  1.  4. -1.]\n",
      " [ 2. -4. -1.  6.]]\n",
      "L:\n",
      " [[ 1.          0.          0.          0.        ]\n",
      " [ 0.42857143  1.          0.          0.        ]\n",
      " [-0.14285714  0.21276596  1.          0.        ]\n",
      " [ 0.28571429 -0.72340426  0.08982036  1.        ]]\n",
      "U:\n",
      " [[ 7.          3.         -1.          2.        ]\n",
      " [ 0.          6.71428571  1.42857143 -4.85714286]\n",
      " [ 0.          0.          3.55319149  0.31914894]\n",
      " [ 0.          0.          0.          1.88622754]]\n",
      "LU:\n",
      " [[ 7.  3. -1.  2.]\n",
      " [ 3.  8.  1. -4.]\n",
      " [-1.  1.  4. -1.]\n",
      " [ 2. -4. -1.  6.]]\n",
      "PA-LU:\n",
      " [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -4.4408921e-16]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00 -4.4408921e-16  0.0000000e+00  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "A = [[7, 3, -1, 2], [3, 8, 1, -4], [-1, 1, 4, -1], [2, -4, -1, 6]]\n",
    "P, L, U = lu_decomposition(A)\n",
    "\n",
    "print(\"A:\\n\",A)\n",
    "print(\"P:\\n\",P)\n",
    "print(\"PA:\\n\",P@A)\n",
    "print(\"L:\\n\",L)\n",
    "print(\"U:\\n\",U)\n",
    "print(\"LU:\\n\",L@U)\n",
    "print(\"PA-LU:\\n\",P@A-L@U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIUFbu8V6HRh",
    "outputId": "04e8c648-c092-4aa6-bbca-324af108e5c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "PA:\n",
      " [[ 7.  3. -1.  2.]\n",
      " [ 3.  8.  1. -4.]\n",
      " [-1.  1.  4. -1.]\n",
      " [ 2. -4. -1.  6.]]\n",
      "l:\n",
      " [[ 1.          0.          0.          0.        ]\n",
      " [ 0.42857143  1.          0.          0.        ]\n",
      " [-0.14285714  0.21276596  1.          0.        ]\n",
      " [ 0.28571429 -0.72340426  0.08982036  1.        ]]\n",
      "u:\n",
      " [[ 7.          3.         -1.          2.        ]\n",
      " [ 0.          6.71428571  1.42857143 -4.85714286]\n",
      " [ 0.          0.          3.55319149  0.31914894]\n",
      " [ 0.          0.          0.          1.88622754]]\n",
      "lu:\n",
      " [[ 7.  3. -1.  2.]\n",
      " [ 3.  8.  1. -4.]\n",
      " [-1.  1.  4. -1.]\n",
      " [ 2. -4. -1.  6.]]\n",
      "pa-lu:\n",
      " [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 -4.4408921e-16]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00 -4.4408921e-16  0.0000000e+00  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import lu\n",
    "p,l,u=lu(A)\n",
    "print(\"p:\\n\",p)\n",
    "print(\"pA:\\n\",p@A)\n",
    "print(\"l:\\n\",l)\n",
    "print(\"u:\\n\",u)\n",
    "print(\"lu:\\n\",l@u)\n",
    "print(\"pA-lu:\\n\",p@A-l@u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32HpfOPMOGIg"
   },
   "outputs": [],
   "source": [
    "# Your solution is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQwdRJSIOGIg"
   },
   "source": [
    "### 4. Block LU (10 pts)\n",
    "\n",
    "Let $A = \\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix}$ be a block matrix. The goal is to solve the linear system\n",
    "\n",
    "$$\n",
    "     \\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} = \\begin{bmatrix} f_1 \\\\ f_2 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "* (2 pts) Using block elimination find matrix $S$ and right-hand side $\\hat{f_2}$ so that $u_2$ can be found from $S u_2 = \\hat{f_2}$. Note that the matrix $S$ is called <span style=\"color:red\">Schur complement</span> of the block $A_{11}$.\n",
    "* (4 pts) Using Schur complement properties prove that \n",
    "\n",
    "$$\\det(X+AB) = \\det(X)\\det(I+BX^{-1}A), $$\n",
    "\n",
    "\n",
    "where $X$ - nonsingular square matrix.\n",
    "* (4 pts) Let matrix $F \\in \\mathbb{R}^{m \\times n}$ and $G \\in \\mathbb{R}^{n \\times m}$. Prove that \n",
    "\n",
    "$$\\det(I_m - FG) = \\det(I_n - GF).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfSI8iKwnvy2"
   },
   "source": [
    "$\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} \\\\ \n",
    "A_{21} & A_{22} \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "L_{11} & 0 \\\\ \n",
    "L_{21} & L_{22} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "U_{11} & U_{12} \\\\ \n",
    "0      & U_{22} \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "L_{11}U_{11} & L_{11}U_{12} \\\\ \n",
    "L_{21}U_{11} & L_{22}U_{22}+L_{21}U_{12} \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhKAaKU2owqt"
   },
   "source": [
    "Gaussian elimination:\n",
    "1.  Factor $A_{11}=L_{11}U_{11}$.\n",
    "2.  Compute $L_{21}=A_{21}U^{−1}_{11}$ and $U_{12}=L^{−1}_{11}A_{12}$\n",
    "3.  Form the Schur complement $S=A_{22} − L_{21}U_{12}=L_{22}U_{22}=A_{22}-A_{21}A_{22}^{-1}A_{12}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJIjoBV_nvdL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ca1wZtbf3FZ"
   },
   "source": [
    "## Problem 2 (eigenvalues)  (50 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiSPofdRoOMF"
   },
   "source": [
    "### 1. Theoretical tasks (15 pts)\n",
    "\n",
    "* (2 pts) Prove that eigenvectors that correspond to distinct eigenvalues are linearly independent.\n",
    "\n",
    "* (3 pts) $A$ is a matrix such that $a_{i,j} \\ge 0$ and $\\sum_{j}a_{i,j} = 1$ (sum of the elements in each row is 1). Prove that $A$ has an eigenvalue $λ=1$ and that any eigenvalue $λ_i$: $|λ_i| \\le 1$.\n",
    "\n",
    "* (5 pts) Prove that normal matrix is Hermitian iff its eigenvalues are real. Prove that normal matrix is unitary iff its eigenvalues satisfy $|λ| = 1$. \n",
    "\n",
    "* (5 pts) The following problem illustrates instability of the Jordan form. Find theoretically the eigenvalues of the perturbed Jordan block (there is only one $ɛ$ - in the left lower corner):\n",
    "\n",
    "$$\n",
    "    J(ɛ) = \n",
    "    \\begin{bmatrix} \n",
    "     λ & 1 & & & 0 \\\\ \n",
    "     0 & λ & 1 & & \\\\ \n",
    "     & 0 & \\ddots & \\ddots & \\\\ \n",
    "     & & 0 & λ & 1 \\\\ \n",
    "     ɛ & & & 0 & λ  \\\\ \n",
    "    \\end{bmatrix}_{n\\times n}\n",
    "$$\n",
    "\n",
    "   Comment how eigenvalues of $J(0)$ are perturbed for large $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b7v2BJB2q-Q"
   },
   "source": [
    "##### (2 pts) Prove that eigenvectors that correspond to distinct eigenvalues are linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve6O6n8tg1-5"
   },
   "source": [
    "Let $A$ be a matrix. Let $[v_1,v_2,…,v_n]$ be eigenvectors corresponding to distinct eigenvalues $[λ_1,λ_2,…,λ_n]$. Then $[v_1,v_2,…,v_n]$ are linearly independent.\n",
    "\n",
    "**Proof by induction**\n",
    "\n",
    "Let $S_k=[v_1,v_2,…,v_k]$.\n",
    "\n",
    "Let $S_k$ is linearly independent if $\\sum_{i=1}^{k}a_iv_i=\\Theta \\Leftrightarrow a_i=\\Theta \\text{ for } i \\in [1,k]$\n",
    "\n",
    "**Base case:**\n",
    "\n",
    "1. An empty set is linearly independent by definition. Therefore, $S_0$ is linearly independent. \n",
    "2. Since eigenvectors are non-zero, $S_1$ is linearly independent.\n",
    "\n",
    "**Inductive step:**\n",
    "\n",
    "Assume that $S_k$ is independent for $1≤k≤n$.\n",
    "\n",
    "Let $\\sum_{i=1}^{k+1}a_iv_i=\\Theta$.\n",
    "\n",
    "$A\\Theta=\\Theta$\n",
    "\n",
    "$\\Theta=A\\Theta=A \\left( \\sum_{i=1}^{k+1}a_iv_i \\right)=\\sum_{i=1}^{k+1}a_iA(v_i)=\\sum_{i=1}^{k+1}a_iλ_iv_i=a_{k+1}λ_{k+1}v_{k+1}+\\sum_{i=1}^{k}a_iλ_iv_i$\n",
    "\n",
    "$\\Theta=λ_{k+1}\\Theta=λ_{k+1}\\left( \\sum_{i=1}^{k+1}a_iv_i \\right)=\\sum_{i=1}^{k+1}a_iλ_{k+1}v_i=a_{k+1}λ_{k+1}v_{k+1}+\\sum_{i=1}^{k}a_iλ_{k+1}v_i$\n",
    "\n",
    "Subtracting the above 2 equations, we get:\n",
    "\n",
    "$\\Theta=\\sum_{i=1}^k a_i(λ_i−λ_{k+1})v_i$\n",
    "\n",
    "Since $S_k$ is linearly independent, $∀i≤k,a_i(λ_i−λ_{k+1})=0$. Since all $λ_i$ are distinct, $∀i≤k,a_i=0$.\n",
    "\n",
    "$\\Theta=\\sum_{i=1}^{k+1}a_iv_i \\Rightarrow a_{k+1}v_{k+1}=\\Theta-\\Theta=\\Theta$\n",
    "\n",
    "Since $v_{k+1}≠\\Theta$ (because eigenvectors are non-zero), $a_{k+1}=0$.\n",
    "\n",
    "Since $∀i≤k+1 \\ a_i=0,\\text{ then } S_{k+1}$ is linearly independent.\n",
    "\n",
    "By the principle of mathematical induction, $S_n$ is linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxCZ1-Vvg18F"
   },
   "source": [
    "##### (3 pts) $A$ is a matrix such that $a_{i,j} \\ge 0$ and $\\sum_{j}a_{i,j} = 1$ (sum of the elements in each row is 1). Prove that $A$ has an eigenvalue $λ=1$ and that any eigenvalue $λ_i$: $|λ_i| \\le 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4-mRJ-oB61e"
   },
   "source": [
    "Let $ v =\\begin{bmatrix} \n",
    "     1 & 1 & ...& 1 \\\\ \n",
    "    \\end{bmatrix}_{1\\times n}\n",
    "$\n",
    "then\n",
    "$\n",
    "    A\\cdot v = \n",
    "    \\begin{bmatrix} \n",
    "     a_{11} & a_{12} & ...& a_{1n} \\\\ \n",
    "     a_{21} & a_{22} & ...& a_{2n} \\\\ \n",
    "     ...    & ...    & ...& ...    \\\\   \n",
    "     a_{n1} & a_{n2} & ...& a_{nn} \\\\\n",
    "    \\end{bmatrix}_{n\\times n}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix} \n",
    "     1 \\\\\n",
    "     1 \\\\\n",
    "     ... \\\\\n",
    "     1 \\\\     \n",
    "    \\end{bmatrix}_{n \\times 1}\n",
    "    =\n",
    "    \\begin{bmatrix} \n",
    "     a_{11} + a_{12} + ...+ a_{1n} \\\\ \n",
    "     a_{21} + a_{22} + ...+ a_{2n} \\\\ \n",
    "     ...    + ...    + ...+ ...    \\\\   \n",
    "     a_{n1} + a_{n2} + ...+ a_{nn} \\\\\n",
    "    \\end{bmatrix}_{n\\times 1}\n",
    "    =\n",
    "    \\begin{bmatrix} \n",
    "     1 \\\\\n",
    "     1 \\\\\n",
    "     ... \\\\\n",
    "     1 \\\\ \n",
    "    \\end{bmatrix}_{n \\times 1}\n",
    "    = 1 \\cdot v \\Rightarrow λ = 1 \\text{ corresponds to the }  v\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTGWwoMuFe7G"
   },
   "source": [
    "Let $|v|_{max}=\\max_i|v_i|$\\\n",
    "Since $Av=λv$, $\\sum_j a_{ij}v_j = λv_i $\\\n",
    "$|λ||v_i|=|\\sum_j a_{ij}v_j| \\leq \\sum_j a_{ij}|v_j| \\leq \\sum_j a_{ij}|v|_{max} =|v|_{max} \\sum_j a_{ij}=|v|_{max}$ for every $v_i \\Rightarrow |λ||v|_{max}\\leq |v|_{max}, |λ| \\leq 1$, **Q.E.D.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkkT__i_E67r"
   },
   "source": [
    "##### (5 pts) Prove that normal matrix is Hermitian if its eigenvalues are real. Prove that normal matrix is unitary if its eigenvalues satisfy $|λ| = 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONZAV74uE6kX"
   },
   "source": [
    "Normal matrix: $AA^* = A^*A$, Hermitian matrix: $A=A^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0gzV_00E6ge"
   },
   "source": [
    "- $Av=λv \\Rightarrow v^*Av=v^*λv=λ\\|v\\|^2_2$\n",
    "- $Av=λv \\Rightarrow v^*A^*=(Av)^*=(λv)^*=λv^* \\Rightarrow v^*A^*v=λv^*v=λ\\|v\\|^2_2=v^*Av \\Rightarrow A^*=A$, **Q.E.D.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66XudMxGOvoq"
   },
   "source": [
    "Unitary matrix: $A^*A=AA^*=I_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLGDFektPA6H"
   },
   "source": [
    "- $Av=λv$\n",
    "- $v^*A^*=(Av)^*=(λv)^*=λ^*v^*$\n",
    "- $v^*A^* \\cdot Av = λ^*v^* \\cdot λv = v^*v \\Rightarrow v^*A^*A = v^* \\Rightarrow A^*A=I_n$\n",
    "- A is the normal matrix, then $AA^*=A^*A=I_n$, **Q.E.D.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXVOY41gZDfv"
   },
   "source": [
    "##### (5 pts) The following problem illustrates instability of the Jordan form. Find theoretically the eigenvalues of the perturbed Jordan block (there is only one $ɛ$ - in the left lower corner):\n",
    "\n",
    "$$\n",
    "    J(ɛ) = \n",
    "    \\begin{bmatrix} \n",
    "     λ & 1 & & & 0 \\\\ \n",
    "     0 & λ & 1 & & \\\\ \n",
    "     & 0 & \\ddots & \\ddots & \\\\ \n",
    "     & & 0 & λ & 1 \\\\ \n",
    "     ɛ & & & 0 & λ  \\\\ \n",
    "    \\end{bmatrix}_{n\\times n}\n",
    "$$\n",
    "Comment how eigenvalues of $J(0)$ are perturbed for large $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzTk_twYZDSa"
   },
   "source": [
    "$\n",
    "    \\det (J(ɛ)-λ_iI_n) = \n",
    "    \\begin{vmatrix} \n",
    "     λ-λ_i & 1 & & & 0 \\\\ \n",
    "     0 & λ-λ_i & 1 & & \\\\ \n",
    "     & 0 & \\ddots & \\ddots & \\\\ \n",
    "     & & 0 & λ-λ_i & 1 \\\\ \n",
    "     ɛ & & & 0 & λ-λ_i  \\\\ \n",
    "    \\end{vmatrix}_{n\\times n}\n",
    "    =\n",
    "    (λ-λ_i)^n +\n",
    "    ɛ\n",
    "    \\begin{vmatrix} \n",
    "     1 & 0& & 0 \\\\ \n",
    "     λ-λ_i & 1 & 0& \\\\ \n",
    "     0 & \\ddots & \\ddots & 0\\\\ \n",
    "     & 0 & λ-λ_i & 1 \\\\ \n",
    "    \\end{vmatrix}_{(n-1)\\times (n-1)}\n",
    "    =\n",
    "    (λ-λ_i)^n +\n",
    "    ɛ\n",
    "    \\begin{vmatrix} \n",
    "     1 & λ-λ_i& & 0 \\\\ \n",
    "     0 & 1 & λ-λ_i & \\\\ \n",
    "     0 & \\ddots & \\ddots & λ-λ_i\\\\ \n",
    "     & 0 & 0 & 1 \\\\ \n",
    "    \\end{vmatrix}_{(n-1)\\times (n-1)}\n",
    "    =\n",
    "    (λ-λ_i)^n +\n",
    "    ɛ \\cdot 1 = 0 \\Rightarrow λ_i = λ-\\sqrt[n]{-ɛ} \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMYPdOZiilKL"
   },
   "source": [
    "$ ɛ=ɛ_0 · e^{i(α+2πk)} $, $ k \\in ℤ $\n",
    "\n",
    "$ -ɛ=ɛ_0 · e^{i(α+π+2πk)} $, $ k \\in ℤ $\n",
    "\n",
    "$ \\sqrt[n]{-ɛ}=\\sqrt[n]{ɛ_0} · e^{i(α+π+2πk)/n} $, $ k \\in ℤ $\\\n",
    "$λ_i = λ-\\sqrt[n]{-ɛ}$ will be evenly distributed in circle around $λ$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWcyqKyrOGIp"
   },
   "source": [
    "### 2. PageRank (35 pts)\n",
    "\n",
    "\n",
    "#### Damping factor importance\n",
    "\n",
    "* (5 pts) Write the function ```pagerank_matrix(G)``` that takes an adjacency matrix $G$ (in both sparse and dense formats) as an input and outputs the corresponding PageRank matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "2jktwIc8OGIp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "# INPUT:  G - np.ndarray or sparse matrix\n",
    "# OUTPUT: A - np.ndarray (of size G.shape) or sparse matrix\n",
    "def pagerank_matrix_dense(G):\n",
    "  n = len(G[0])\n",
    "  for i in range(n):\n",
    "    n_neighbors=sum(G[:,i])\n",
    "    G[:,i]=np.divide(G[:,i],n_neighbors)\n",
    "  A=np.empty(n)\n",
    "  A.fill(1.0/n)\n",
    "  A_temp=np.empty(n)\n",
    "  while(1):\n",
    "    A_temp = np.matmul(G,A)\n",
    "    if(LA.norm(A_temp-A)<1e-7):\n",
    "      break\n",
    "    A=A_temp.copy()\n",
    "  \n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJYOBpNWO64G",
    "outputId": "73d1a78e-885f-4cf9-e47c-6cf2df3ef777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12499998, 0.1875    , 0.37500004, 0.31249999])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank_matrix_dense(np.array([[0,0,1,0],[1,0,1,0],[1,0,0,1],[0,1,1,0]],dtype='float' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtVmgGnYOGIs"
   },
   "source": [
    "* (3 pts) Find PageRank matrix $A$ that corresponds to the following graph: <img src=\"https://github.com/oseledets/nla2021/blob/master/hw/hw2/graph.png?raw=1\" width='250'>\n",
    "What is its largest eigenvalue? What multiplicity does it have?\n",
    "\n",
    "\n",
    "* (5 pts) Implement the power method for a given matrix $A$, an initial guess $x_0$ and a number of iterations ```num_iter```. It should be organized as a function ```power_method(A, x0, num_iter)``` that outputs approximation to eigenvector $x$, eigenvalue $λ$ and history of residuals $\\{\\|Ax_k - λ_k x_k\\|_2\\}$. Make sure that the method converges to the correct solution on a matrix $\\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}$ which is known to have the largest eigenvalue equal to $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLo7A--rOGIs"
   },
   "outputs": [],
   "source": [
    "# INPUT:  A - np.ndarray (2D), x0 - np.ndarray (1D), num_iter - integer (positive)\n",
    "# OUTPUT: x - np.ndarray (of size x0), l - float, res - np.ndarray (of size num_iter + 1 [include initial guess])\n",
    "def power_method(A, x0, num_iter): # 5 pts\n",
    "    # enter your code here\n",
    "    return x, l, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hAowO6zOGIu"
   },
   "source": [
    "* (2 pts) Run the power method for the graph presented above and plot residuals $\\|Ax_k - λ_k x_k\\|_2$ as a function of $k$ for ```num_iter=100``` and random initial guess ```x0```.  Explain the absence of convergence. \n",
    "\n",
    "\n",
    "* (2 pts) Consider the same graph, but with additional self loop at node 4 (self loop is an edge that connects a vertex with itself). Plot residuals as in the previous task and discuss the convergence. Now, run the power method with ```num_iter=100``` for 10 different initial guesses and print/plot the resulting approximated eigenvectors. Why do they depend on the initial guess?\n",
    "\n",
    "\n",
    "In order to avoid this problem Larry Page and Sergey Brin [proposed](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf) to use the following regularization technique:\n",
    "\n",
    "$$\n",
    "A_d = dA + \\frac{1-d}{N} \\begin{pmatrix} 1 & \\dots & 1 \\\\ \\vdots & & \\vdots \\\\ 1 & \\dots & 1 \\end{pmatrix},\n",
    "$$\n",
    "\n",
    "where $d$ is a small parameter in $[0,1]$ (typically $d=0.85$), which is called **damping factor**, $A$ is of size $N\\times N$. Now $A_d$ is the matrix with multiplicity of the largest eigenvalue equal to 1. \n",
    "Recall that computing the eigenvector of the PageRank matrix, which corresponds to the largest eigenvalue, has the following interpretation. Consider a person who stays in a random node of a graph (i.e. opens a random web page); at each step s/he follows one of the outcoming edges uniformly at random (i.e. opens one of the links). So the person randomly walks through the graph and the eigenvector we are looking for is exactly his/her stationary distribution â€” for each node it tells you the probability of visiting this particular node. Therefore, if the person has started from a part of the graph which is not connected with the other part, he will never get there.  In the regularized model, the person at each step follows one of the outcoming links with probability $d$ OR teleports to a random node from the whole graph with probability $(1-d)$.\n",
    "\n",
    "* (2 pts) Now, run the power method with $A_d$ and plot residuals $\\|A_d x_k - λ_k x_k\\|_2$ as a function of $k$ for $d=0.97$, ```num_iter=100``` and a random initial guess ```x0```.\n",
    "\n",
    "* (5 pts) Find the second largest in the absolute value eigenvalue of the obtained matrix $A_d$. How and why is it connected to the damping factor $d$? What is the convergence rate of the PageRank algorithm when using damping factor?\n",
    "\n",
    "Usually, graphs that arise in various areas are sparse (social, web, road networks, etc.) and, thus, computation of a matrix-vector product for corresponding PageRank matrix $A$ is much cheaper than $\\mathcal{O}(N^2)$. However, if $A_d$ is calculated directly, it becomes dense and, therefore, $\\mathcal{O}(N^2)$ cost grows prohibitively large for  big $N$.\n",
    "\n",
    "\n",
    "* (2 pts) Implement fast matrix-vector product for $A_d$ as a function ```pagerank_matvec(A, d, x)```, which takes a PageRank matrix $A$ (in sparse format, e.g., ```csr_matrix```), damping factor $d$ and a vector $x$ as an input and returns $A_dx$ as an output. \n",
    "\n",
    "* (1 pts) Generate a random adjacency matrix of size $10000 \\times 10000$ with only 100 non-zero elements and compare ```pagerank_matvec``` performance with direct evaluation of $A_dx$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o3LKx5UOGIv"
   },
   "outputs": [],
   "source": [
    "# INPUT:  A - np.ndarray (2D), d - float (from 0.0 to 1.0), x - np.ndarray (1D, size of A.shape[0/1])\n",
    "# OUTPUT: y - np.ndarray (1D, size of x)\n",
    "def pagerank_matvec(A, d, x): # 2 pts\n",
    "    # enter your code here\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru70NGUlOGIy"
   },
   "source": [
    "#### DBLP: computer science bibliography\n",
    "\n",
    "Download the dataset from [here](https://goo.gl/oZVxEa), unzip it and put `dblp_authors.npz`  and `dblp_graph.npz` in the same folder with this notebook. Each value (author name) from `dblp_authors.npz` corresponds to the row/column of the matrix from `dblp_graph.npz`. Value at row `i` and column `j` of the matrix from `dblp_graph.npz` corresponds to the number of times author `i` cited papers of the author `j`. Let us now find the most significant scientists according to PageRank model over DBLP data.\n",
    "\n",
    "* (4 pts) Load the weighted adjacency matrix and the authors list into Python using ```load_dblp(...)``` function. Print its density (fraction of nonzero elements). Find top-10 most cited authors from the weighted adjacency matrix. Now, make all the weights of the adjacency matrix equal to 1 for simplicity (consider only existence of connection between authors, not its weight). Obtain the PageRank matrix $A$ from the adjacency matrix and verify that it is stochastic.\n",
    " \n",
    " \n",
    "* (1 pts) In order to provide ```pagerank_matvec``` to your ```power_method``` (without rewriting it) for fast calculation of $A_dx$, you can create a ```LinearOperator```: \n",
    "```python\n",
    "L = scipy.sparse.linalg.LinearOperator(A.shape, matvec=lambda x, A=A, d=d: pagerank_matvec(A, d, x))\n",
    "```\n",
    "Calling ```L@x``` or ```L.dot(x)``` will result in calculation of ```pagerank_matvec(A, d, x)``` and, thus, you can plug $L$ instead of the matrix $A$ in the ```power_method``` directly. **Note:** though in the previous subtask graph was very small (so you could disparage fast matvec implementation), here it is very large (but sparse), so that direct evaluation of $A_dx$ will require $\\sim 10^{12}$ matrix elements to store - good luck with that (^_<).\n",
    "\n",
    "\n",
    "* (2 pts) Run the power method starting from the vector of all ones and plot residuals $\\|A_dx_k - λ_k x_k\\|_2$  as a function of $k$ for $d=0.85$.\n",
    "\n",
    "\n",
    "* (1 pts) Print names of the top-10 authors according to PageRank over DBLP when $d=0.85$. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5ZnW7m-OGIz"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import numpy as np\n",
    "def load_dblp(path_auth, path_graph):\n",
    "    G = load_npz(path_graph).astype(float)\n",
    "    with np.load(path_auth) as data: authors = data['authors']\n",
    "    return G, authors\n",
    "G, authors = load_dblp('dblp_authors.npz', 'dblp_graph.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QynfixvjOGI1"
   },
   "outputs": [],
   "source": [
    "# Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ2vaIyMOGI3"
   },
   "source": [
    "## Problem 3. QR algorithm (33 pts)\n",
    "\n",
    "* Implement QR-algorithm without shifts. Prototype of the function is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMHBZLojOGI3"
   },
   "outputs": [],
   "source": [
    "# INPUT: \n",
    "# A_init - square matrix, \n",
    "# num_iter - number of iterations for QR algorithm\n",
    "# OUTPUT: \n",
    "# Ak - transformed matrix A_init given by QR algorithm, \n",
    "# convergence - numpy array of shape (num_iter, ), \n",
    "# where we store the maximal number from the Chebyshev norm \n",
    "# of triangular part of the Ak for every iteration\n",
    "def qr_algorithm(A_init, num_iter): # 3 pts\n",
    "    # enter your code here\n",
    "    return Ak, convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNrCBNRUOGI6"
   },
   "source": [
    "#### Symmetric case (3 pts)\n",
    "- Create symmetric tridiagonal $11 \\times 11$ matrix with elements $-1, 2, -1$ on sub-, main- and upper diagonal respectively without using loops.\n",
    "- Run $400$ iterations of the QR algorithm for this matrix.\n",
    "- Plot the output matrix with function ```plt.spy(Ak, precision=1e-7)```.\n",
    "- Plot convergence of QR-algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuKwQGXbOGI6"
   },
   "outputs": [],
   "source": [
    "# Your solution is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lomV2K-OGI8"
   },
   "source": [
    "#### Nonsymmetric case (5 pts)\n",
    "\n",
    "- Create nonsymmetric tridiagonal $11 \\times 11$ matrix with elements $5, 3, -2$ on sub-, main- and upper diagonal respectively without using loops.\n",
    "- Run $250$ iterations of the QR algorithm for this matrix.\n",
    "- Plot the result matrix with function ```plt.spy(Ak, precision=1e-7)```. Is this matrix lower triangular? How does this correspond to the claim about convergence of the QR algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2lGBHjaOGI9"
   },
   "outputs": [],
   "source": [
    "# Your solution is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGEq2np3f3Fg"
   },
   "source": [
    "### QR algorithms with Rayleigh Quotient shift (10 pts)\n",
    "\n",
    "In the lectures the Rayleigh Quotient shift was introduced to speed up convergence of power method. Here we ask you to generalize this approach to construct the shifts in QR algorithm.\n",
    "\n",
    "- How to compute the Rayleigh Quotient shift in QR algorithm fast? Provide formulas and explanations how they can be simplified.\n",
    "- Implement explicit QR algorithm with Rayleigh Quotient shift. Please do not worry about implicit orthogonalization, we want to compare convergence only in terms of iterations.\n",
    "- Test your implementation in the symmetric case. Plot the convergence of QR algorithm with and without shift. Choose the dimension $n \\sim 100 $ for more representative results. \n",
    "- How the convergence of the shifted algorithm compares to the simple QR? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TdOYWh9f3Fg"
   },
   "outputs": [],
   "source": [
    "def qr_algorithm_reileigh(A_init, num_iter):\n",
    "    # enter your code here\n",
    "    return Ak, convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enepxqPYf3Fh"
   },
   "source": [
    "- Try QR with Rayleigh Quotient shift for a simple matrix $A = \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}$. Does anything change from iteration to iteration? Does shift affect convergence here? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXxmGFVYf3Fh"
   },
   "outputs": [],
   "source": [
    "# Your solution is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQdjUHQIf3Fh"
   },
   "source": [
    "### QR with Wilkinson shift  (15 pts)\n",
    "\n",
    "To solve the problem that appears in the last example, we can use the Wilkinson shift:\n",
    "\n",
    "$$\\mu = a_m - \\frac {sign(\\delta) b^2_{m-1}} {(|\\delta| + \\sqrt{\\delta^2 + b^2_{m-1}} )},$$\n",
    "\n",
    "where $\\delta = \\frac{(a_{m-1} - a_m)}{2}$. If $\\delta = 0$, then instead of $sign(\\delta)$ you have to choose $1$ or $-1$ arbitrary.\n",
    "The numbers $a_m, b_{m-1}, a_{m-1}$ are taken from matrix $B$:\n",
    "\n",
    "$$\n",
    "    B = \n",
    "    \\begin{bmatrix} \n",
    "     a_{m-1} & b_{m-1} \\\\ \n",
    "     b_{m-1} & a_m \\\\ \n",
    "    \\end{bmatrix},\n",
    "$$  \n",
    "which is a lower right bottom submatrix of $A^{(k)}$. Here $k$ is an iteration counter in QR algorithm.\n",
    "\n",
    "- Compare convergence in the symmetric cases: \n",
    "    - distinctive eigenvalues\n",
    "    - two coincident eigenvalues\n",
    "    - maximum and minimum eigenvalues with the same absolute value\n",
    "Choose the dimension $n \\sim 100 $ for more representative results.\n",
    "What do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82lMlR6uf3Fh"
   },
   "outputs": [],
   "source": [
    "def qr_algorithm_wilkinson(A_init, num_iter):\n",
    "    # enter your code here\n",
    "    return Ak, convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0AdzqEbf3Fh"
   },
   "outputs": [],
   "source": [
    "# Your solution is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_8OYe7wOGI-"
   },
   "source": [
    "## Problem 4. (Movie Recommender system) 15 pts\n",
    "\n",
    "Imagine the world without NLA where you have free evenings and you can watch movies!  \n",
    "But it is always hard to choose a movie to watch. \n",
    "In this problem we suggest you to build your own movie recommender system based on SVD decomposition, so you can combine two perfect things: Numerical Linear Algebra and cinematography!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2duSA-Su7CI"
   },
   "source": [
    "In order to build recommender system you need data. \n",
    "Here you are https://grouplens.org/datasets/movielens/1m/\n",
    "\n",
    "Usually all recommender systems may be devided into two groups\n",
    "\n",
    "#### Collaborative filtering. \n",
    "\n",
    "This approach is based on user-item interaction.\n",
    "It has one important assumption: user who has liked an item in the past will also likes the same in the future. Suppose the user A likes the films about vampires. \n",
    "He is Twilight saga fan and he has watched the film \"What we do in the shadows\" and liked it or unliked it, in other words he evaluated it somehow. And suppose another user B, who has the similair behavior to the first user (he is also Twilight saga fan). And the chance, that he will estimate \"What we do in the shadows\" in the same way that user A did, is huge. So, the purpose of the collaborative filtering is to predict a user's behavior based on behavior of the simular users.\n",
    "\n",
    "#### Content based filtering.\n",
    "\n",
    "Collaborative filtering has some essential flaws. The main one is called \"cold start\". \"Cold start\" happens when the new user comes and he has not react anyhow to the items. So we do not know his past behavior and we do not know what to advise. Here content based filtering helps. Often resources gather some extra info about users and items before a user comes down to utilising the resource. So, for example we would know that user likes horror movies before he watched anything on the resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMvQV1zSu7Cg"
   },
   "source": [
    "\n",
    "- In this task you will implement Collaborative filtering based on SVD (we will use the function from the proper package and check if the result recommender system advices the similar movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMN7EK6gu7Ch"
   },
   "source": [
    "1) (1 pts)  Explore the data. Construct the interaction matrix $M$ of size $m \\times n$ which contains the information of how a certain user rated a certain film. \n",
    "\n",
    "2) (5 pts)  Compute SVD of this matrix. Remeber that matrix $M$ is sparse (one user can hardly watch all the movies) so the good choice would be to use method from ```scipy.sparse.linalg``` package\n",
    "\n",
    "$$ M = USV^{\\top}, $$\n",
    "\n",
    "where $U$ is a $m \\times r $ orthogonal matrix with left singular vectors, which represents the relationship between users and latent factors, $S$ is a $r \\times r $ diagonal matrix, which describes the strength of each latent factor and $V^\\top$ is a $r \\times n$ matrix with right singular vectors, which represent the embeddings of  items (movies in our case) in latent space.\n",
    "Describe any simple heuristic to choose appropriate value for $r$ and explain why do you expect that it will work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxYtnm7au7Ci"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "\n",
    "# Create the interaction matrix\n",
    "\n",
    "# Normalize the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zUd9OvBu7Cj"
   },
   "outputs": [],
   "source": [
    "# Compute Singular Value Decomposition of interaction matrix. You can use built-in functions\n",
    "\n",
    "U,S, V = svd(M) # Update this line, it is just example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMXnKF5Tu7Cj"
   },
   "source": [
    "3) (2 pts) In order to get weighted item-latent factors, we can multiply $S$ and $V^{T}$. Please, remember that $S$ is diagonal and multiply them efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEW4M5Ovu7Cj"
   },
   "outputs": [],
   "source": [
    "# Your solutuion is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEMDQkkqu7Ck"
   },
   "source": [
    "Now we have vectors that represent our item space. In other words we have $N$ movies and $N$ vectors which describe each movie, a.k.a. embeddings. \n",
    "In order to know if two movies are similar or not we need just to check if the corresponding vectors are similair or not. How we can do this?\n",
    "\n",
    "4) (2 pts)  Implement the cosine metric. If the cosine metric between two vectors equals to $1$ both vectors are collinear, if $0$ vectors are orthogonal, as a result corresponding movies are completely different.\n",
    "\n",
    "$$\n",
    "cosine(u,v) = \\frac{u^{\\top}v}{\\|u\\|_2\\|v\\|_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAR4dXMOOGI_"
   },
   "outputs": [],
   "source": [
    "# Your solutuion is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wRZh8ALu7C1"
   },
   "source": [
    "5) (5 pts) Check your result. Implement the fuction, which finds and prints $k$ similar movies to the one you have chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26g7MzeWu7C1"
   },
   "outputs": [],
   "source": [
    "# Your solutuion is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPIQfKcmu7C2"
   },
   "source": [
    "Enjoy watching the recommended movies!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "OxCZ1-Vvg18F",
    "RkkT__i_E67r",
    "YXVOY41gZDfv"
   ],
   "name": "lna_hw2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
